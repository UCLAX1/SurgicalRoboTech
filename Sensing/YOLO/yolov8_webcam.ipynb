{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:12:45.521983Z",
     "start_time": "2024-04-27T23:12:44.227041Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "import cv2\n",
    "import numpy as np\n",
    "model = YOLO(\"yolov8n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrus']\n"
     ]
    }
   ],
   "source": [
    "# model classes -> array\n",
    "file = open(\"modelIDs_form.txt\")\n",
    "model_classes_unf = file.readlines()\n",
    "model_classes = [x[:-1] for x in model_classes_unf]\n",
    "print(model_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n\")\n",
    "\n",
    "results = model.predict(source=\"0\", show = True)\n",
    "model.predict()\n",
    "# print(results)\n",
    "# boxes = results.boxes\n",
    "# for box in boxes:\n",
    "#     print(box.xyxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"Zpgzmf5fPC3TsR3Qo9CW\")\n",
    "project = rf.workspace(\"x1-robotics\").project(\"x1-robotics\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model with mps\n",
    "results = model.train(data='data.yaml', epochs=100, imgsz=640, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Perform inference on an image\n",
    "results = model.predict(source=\"0\", show = True)\n",
    "\n",
    "# Extract bounding boxes, classes, names, and confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:18:44.855459Z",
     "start_time": "2024-04-27T23:18:44.577401Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/sara/Documents/My-Documents/YOLO/people.jpg: 288x640 16 persons, 37.0ms\n",
      "Speed: 1.4ms preprocess, 37.0ms inference, 0.3ms postprocess per image at shape (1, 3, 288, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "Found a human\n",
      "tensor([[607.3201,  70.2686, 746.8383, 378.9189]])\n",
      "tensor([[299.0244,  58.7080, 429.2019, 389.6456]])\n",
      "tensor([[510.1601,  76.1782, 638.8001, 384.3613]])\n",
      "tensor([[881.4597,  85.2389, 985.2129, 379.1891]])\n",
      "tensor([[  5.5257,  77.8505, 123.8829, 379.8596]])\n",
      "tensor([[438.6526,  74.4641, 526.9936, 388.6803]])\n",
      "tensor([[734.1814,  60.1753, 807.0663, 367.0087]])\n",
      "tensor([[165.6914,  86.1188, 260.6622, 382.3496]])\n",
      "tensor([[239.2636,  75.0779, 314.9918, 378.0825]])\n",
      "tensor([[764.1459,  63.8035, 872.4256, 382.3545]])\n",
      "tensor([[ 99.3930, 101.9070, 173.1324, 376.6554]])\n",
      "tensor([[853.4208,  74.8674, 911.8937, 373.4976]])\n",
      "tensor([[395.3681,  78.5862, 453.8930, 363.7690]])\n",
      "tensor([[587.0694,  73.6743, 649.3521, 381.6407]])\n",
      "tensor([[158.9483,  86.8679, 208.1806, 373.7433]])\n",
      "tensor([[287.3726,  86.9258, 338.7453, 369.1790]])\n"
     ]
    }
   ],
   "source": [
    "print(model.names)\n",
    "results = model.predict(source=\"people.jpg\")  # generator of Results objects\n",
    "vip_Boxes = []\n",
    "for r in results:\n",
    "    boxes = r.boxes  # Boxes object for bbox outputs\n",
    "    masks = r.masks  # Masks object for segment masks outputs\n",
    "    probs = r.probs  # Class probabilities for classification outputs\n",
    "    for box in boxes:\n",
    "        if(box.cls == 0):\n",
    "            print(\"Found a human\")\n",
    "            vip_Boxes.append(box)\n",
    "for box in vip_Boxes:\n",
    "    print(box.xyxy)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
